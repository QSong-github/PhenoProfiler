{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test BR00115133-31 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: mkdir filepath to save dataset\n",
    "\n",
    "# !mkdir -p '../dataset/cpg0001/2020_08_11_Stain3_Yokogawa/'\n",
    "\n",
    "# Step 2: dowaload 2020_08_11_Stain3_Yokogawa dataset, about 70G\n",
    "# !aws s3 sync s3://cellpainting-gallery/cpg0001-cellpainting-protocol/source_4/images/2020_08_11_Stain3_Yokogawa/ ./2020_08_11_Stain3_Yokogawa --no-sign-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # move noise images such as DC_ to others\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # 源目录和目标目录\n",
    "# source_dir = \"/data/boom/cpg0001/2020_08_11_Stain3_Yokogawa/images/BR00115134/\"\n",
    "# target_dir = \"/data/boom/cpg0001/2020_08_11_Stain3_Yokogawa/images/others/\"\n",
    "\n",
    "# # 确保目标目录存在\n",
    "# os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# # 遍历源目录中的所有文件\n",
    "# for filename in os.listdir(source_dir):\n",
    "#     file_path = os.path.join(source_dir, filename)\n",
    "    \n",
    "#     # 只处理文件（跳过子目录）\n",
    "#     if os.path.isfile(file_path):\n",
    "#         # 检查文件名是否不以\"BR00\"开头\n",
    "#         if not filename.startswith(\"BR00\"):\n",
    "#             target_path = os.path.join(target_dir, filename)\n",
    "            \n",
    "#             # 移动文件\n",
    "#             shutil.move(file_path, target_path)\n",
    "#             # print(f\"Moved: {filename} -> {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make CSV file\n",
    "\n",
    "# import os\n",
    "# import csv\n",
    "\n",
    "# # 指定包含tif文件的文件夹路径\n",
    "# folder_path = '/data/boom/cpg0001/2020_08_11_Stain3_Yokogawa/images/BR00115134/'\n",
    "\n",
    "# # 指定输出CSV文件的路径\n",
    "# output_csv_path = '/data/boom/cpg0001/2020_08_11_Stain3_Yokogawa/images/BR00115134.csv'\n",
    "\n",
    "# # 获取文件夹中所有的tif文件\n",
    "# tif_files = [f for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
    "\n",
    "# # 获取文件夹中所有的tif文件，并按照文件名排序\n",
    "# tif_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.tif')])\n",
    "\n",
    "# # 将文件名写入CSV文件\n",
    "# with open(output_csv_path, mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     for file_name in tif_files:\n",
    "#         writer.writerow([file_name])\n",
    "\n",
    "# print(f\"All .tif files have been written to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.transform import resize\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from huggingface_mae import MAEModel\n",
    "from utils import *\n",
    "\n",
    "class PDDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, CSV_path):\n",
    "        self.image_path = image_path\n",
    "        self.image_files_CSV = pd.read_csv(CSV_path, header=None)  # 只取文件名列\n",
    "        self.image_files = self.image_files_CSV[0].tolist()\n",
    "        self.total_images = len(self.image_files)\n",
    "        print(len(self.image_files))\n",
    "        \n",
    "        # 确保图像数量是5的倍数\n",
    "        assert self.total_images % 5 == 0, \"图像总数必须是5的倍数\"\n",
    "        self.num_groups = self.total_images // 5\n",
    "        \n",
    "        # 预处理转换\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def load_image(self, img_name):\n",
    "        img_path = os.path.join(self.image_path, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        return np.array(image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 计算5个图像的起始位置\n",
    "        start_idx = idx * 5\n",
    "        \n",
    "        # 加载5个连续的图像\n",
    "        images = []\n",
    "        for i in range(5):\n",
    "            img_name = self.image_files[start_idx + i]\n",
    "            img_array = self.load_image(img_name)\n",
    "            images.append(img_array)\n",
    "        \n",
    "        # 堆叠图像并调整大小 (5, H, W) -> (5, 448, 448)\n",
    "        images = np.stack(images, axis=0)\n",
    "        images = resize(images, (5, 256, 256), anti_aliasing=True)\n",
    "        \n",
    "        # 转换为张量 (5, 448, 448) -> (5, 448, 448)\n",
    "        images = torch.from_numpy(images).float()\n",
    "        \n",
    "        return {'image': images}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "image_files = pd.read_csv('/data/boom/cpg0001/2020_08_11_Stain3_Yokogawa/images/BR00115134.csv', header=None)  # 只取文件名列\n",
    "# image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loaders_inference(batch_size):\n",
    "    print(\"Building loaders\")\n",
    "    dataset = PDDDataset(\n",
    "        image_path=\"/data/boom/cpg0001/2020_08_11_Stain3_Yokogawa/images/BR00115134/\",\n",
    "        CSV_path=\"/data/boom/cpg0001/2020_08_11_Stain3_Yokogawa/images/BR00115134.csv\"\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=4, \n",
    "        pin_memory=True, \n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    print(f\"Total batches: {len(test_loader)}\")\n",
    "    return test_loader\n",
    "\n",
    "def get_image_embeddings(model_path, model, batch_size):\n",
    "    test_loader = build_loaders_inference(batch_size)\n",
    "    model = model.eval().cuda()\n",
    "    \n",
    "    print(\"Finished loading model\")\n",
    "    test_image_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            \n",
    "            # Run prediction\n",
    "            model.return_channelwise_embeddings = False\n",
    "            image_embeddings = model.predict(batch[\"image\"].cuda())\n",
    "            \n",
    "            # Reshape back if needed (depending on your model output)\n",
    "            test_image_embeddings.append(image_embeddings)\n",
    "            # print(image_embeddings.shape)\n",
    "            # break\n",
    "    \n",
    "    return torch.cat(test_image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/boom/PhenoProfiler/Baseline/OpenPhenom/huggingface_mae.py:291: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(modelpath, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building loaders\n",
      "7680\n",
      "Total batches: 8\n",
      "Finished loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/bob/anaconda3/envs/boom/lib/python3.11/site-packages/torch/nn/modules/instancenorm.py:88: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n",
      "100%|██████████| 8/8 [26:16<00:00, 197.03s/it]  \n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"recursionpharma/OpenPhenom\"\n",
    "save_path = \"output/BR00115134/\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# 加载模型\n",
    "model = MAEModel.from_pretrained(MODEL_PATH).cuda()\n",
    "img_embeddings = get_image_embeddings(MODEL_PATH, model, batch_size=200)  # change batch_size to fit your device\n",
    "features = img_embeddings.cpu().numpy()\n",
    "\n",
    "np.save(save_path + \"OpenPhenom_BR00115134_test\" + \".npy\", features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 384)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "save_path = \"output/BR00115134/\"\n",
    "\n",
    "# features = np.load(save_path+\"OpenPhenom_BR00115134_test.npy\").T\n",
    "# save_path = 'output/BR00115134/'\n",
    "REG_PARAM = 1e-2\n",
    "num_features = features.shape[1]\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate csv like below_csv, which have plate well and treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/bob/boom/PhenoProfiler/revision/BBBC022/PhenoProfiler/0_noBC_well_level.csv'\n",
    "\n",
    "# csv = pd.read_csv(path)\n",
    "\n",
    "# csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make GT of MOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 11)\n"
     ]
    }
   ],
   "source": [
    "# read JUMP-MOA_compound_platemap_with_metadata.txt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "meta = pd.read_csv('/home/bob/boom/PhenoProfiler/output/JUMP-MOA_compound_platemap_with_metadata.txt', sep='\\t')  # assuming it's tab-delimited\n",
    "print(meta.shape)  # meta['moa']\n",
    "# meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['trt', 'control'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta['pert_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_567401/1172509567.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n"
     ]
    }
   ],
   "source": [
    "# 整合成 Well Trt Features 的形式\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "# save_path = 'output/BR00115134/'\n",
    "REG_PARAM = 1e-2\n",
    "# num_features = 672\n",
    "\n",
    "# features = np.load(save_path + \"DeepProfiler_alltrain_25test.npy\").T\n",
    "# meta = pd.read_csv('output/JUMP-MOA_compound_platemap_with_metadata.txt', sep='\\t')\n",
    "\n",
    "# 检查数据形状是否匹配\n",
    "assert len(meta) == features.shape[0] // 4, \"Meta数据行数与特征数据不匹配\"\n",
    "\n",
    "# 特征聚合：每4行取平均\n",
    "aggregated_features = np.zeros((len(meta), num_features))\n",
    "for i in range(len(meta)):\n",
    "    start_idx = i * 4\n",
    "    end_idx = start_idx + 4\n",
    "    aggregated_features[i] = features[start_idx:end_idx].mean(axis=0)\n",
    "\n",
    "# 创建结果DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'Well': meta['well_position'],\n",
    "    'Treatment': meta['pert_type'],\n",
    "    'broad_sample':meta['broad_sample']\n",
    "})\n",
    "\n",
    "# 添加聚合后的特征\n",
    "feature_columns = [i for i in range(num_features)]\n",
    "result_df[feature_columns] = aggregated_features\n",
    "\n",
    "# 保存为CSV文件\n",
    "# output_path = save_path + 'DeepProfiler_Wells_NoBC.csv'\n",
    "# result_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC Sphering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "import pandas as pd\n",
    "\n",
    "class WhiteningNormalizer(object):\n",
    "    def __init__(self, controls, reg_param=1e-6):\n",
    "        # Whitening transform on population level data\n",
    "        self.mu = controls.mean()\n",
    "        self.whitening_transform(controls - self.mu, reg_param, rotate=True)\n",
    "        # print(self.mu.shape, self.W.shape)\n",
    "        \n",
    "    def whitening_transform(self, X, lambda_, rotate=True):\n",
    "        C = (1/X.shape[0]) * np.dot(X.T, X)\n",
    "        s, V = scipy.linalg.eigh(C)\n",
    "        D = np.diag( 1. / np.sqrt(s + lambda_) )\n",
    "        W = np.dot(V, D)\n",
    "        if rotate:\n",
    "            W = np.dot(W, V.T)\n",
    "        self.W = W\n",
    "\n",
    "    def normalize(self, X):\n",
    "        return np.dot(X - self.mu, self.W)\n",
    "\n",
    "columns2 = [i for i in range(num_features)]  #　(672)\n",
    "REG_PARAM = 1e-2\n",
    "\n",
    "wells = result_df\n",
    "whN = WhiteningNormalizer(wells.loc[wells[\"Treatment\"] == \"control\", columns2], reg_param=REG_PARAM)\n",
    "\n",
    "whD = whN.normalize(wells[columns2])\n",
    "\n",
    "# Save whitened profiles\n",
    "wells[columns2] = whD\n",
    "\n",
    "# wells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 387)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment-level profiles / Mean Aggreagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 387)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "# Aggregate profiles\n",
    "columns1 = [\"Well\", \"broad_sample\"]\n",
    "columns2 = [i for i in range(num_features)]\n",
    "\n",
    "wells_1 = wells.drop(columns=[\"Well\"])\n",
    "\n",
    "profiles = wells_1.groupby([\"broad_sample\", 'Treatment']).mean().reset_index()\n",
    "\n",
    "# 将 meta 的 broad_sample 和 moa 转为字典\n",
    "moa_dict = meta.set_index('broad_sample')['moa'].to_dict()\n",
    "\n",
    "# 用 map 添加 moa 列\n",
    "profiles['moa'] = profiles['broad_sample'].map(moa_dict)\n",
    "\n",
    "# profiles = wells_1[[\"Treatment\", \"broad_sample\"] + columns2]\n",
    "# # profiles\n",
    "print(profiles.shape)\n",
    "# profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 90)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 6. Similarity matrix\n",
    "# Compute Cosine Similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "COS = cosine_similarity(profiles[columns2], profiles[columns2])\n",
    "COS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>moa_x</th>\n",
       "      <th>moa_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRD-A12994259-001-02-1</td>\n",
       "      <td>BRD-A12994259-001-02-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>tumor necrosis factor production inhibitor</td>\n",
       "      <td>tumor necrosis factor production inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRD-A22769835-300-05-7</td>\n",
       "      <td>BRD-A12994259-001-02-1</td>\n",
       "      <td>0.165413</td>\n",
       "      <td>antihistamine</td>\n",
       "      <td>tumor necrosis factor production inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRD-A53576514-048-14-3</td>\n",
       "      <td>BRD-A12994259-001-02-1</td>\n",
       "      <td>0.299385</td>\n",
       "      <td>acetylcholine receptor antagonist</td>\n",
       "      <td>tumor necrosis factor production inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRD-A78210457-001-01-5</td>\n",
       "      <td>BRD-A12994259-001-02-1</td>\n",
       "      <td>0.287150</td>\n",
       "      <td>MDM inhibitor</td>\n",
       "      <td>tumor necrosis factor production inhibitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRD-A87435144-001-01-6</td>\n",
       "      <td>BRD-A12994259-001-02-1</td>\n",
       "      <td>-0.102513</td>\n",
       "      <td>pyruvate dehydrogenase kinase inhibitor</td>\n",
       "      <td>tumor necrosis factor production inhibitor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    index                variable     value  \\\n",
       "0  BRD-A12994259-001-02-1  BRD-A12994259-001-02-1  1.000000   \n",
       "1  BRD-A22769835-300-05-7  BRD-A12994259-001-02-1  0.165413   \n",
       "2  BRD-A53576514-048-14-3  BRD-A12994259-001-02-1  0.299385   \n",
       "3  BRD-A78210457-001-01-5  BRD-A12994259-001-02-1  0.287150   \n",
       "4  BRD-A87435144-001-01-6  BRD-A12994259-001-02-1 -0.102513   \n",
       "\n",
       "                                        moa_x  \\\n",
       "0  tumor necrosis factor production inhibitor   \n",
       "1                               antihistamine   \n",
       "2           acetylcholine receptor antagonist   \n",
       "3                               MDM inhibitor   \n",
       "4     pyruvate dehydrogenase kinase inhibitor   \n",
       "\n",
       "                                        moa_y  \n",
       "0  tumor necrosis factor production inhibitor  \n",
       "1  tumor necrosis factor production inhibitor  \n",
       "2  tumor necrosis factor production inhibitor  \n",
       "3  tumor necrosis factor production inhibitor  \n",
       "4  tumor necrosis factor production inhibitor  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to tidy format\n",
    "df = pd.DataFrame(data=COS, index=list(profiles.broad_sample), columns=list(profiles.broad_sample))\n",
    "#　将行索引重置为默认整数索引，并将原来的行索引 broad_sample 转换为一列，命名为 index。所以，variable　表示原来的broad_sample名。\n",
    "df = df.reset_index().melt(id_vars=[\"index\"])\n",
    "# df # 其中每一行都表示 预测的Treatment和 GT 之间的概率。\n",
    "\n",
    "# Annotate rows\n",
    "df2 = pd.merge(\n",
    "    df, \n",
    "    profiles[[\"broad_sample\", \"moa\"]],  # 为了加 Metadata_moa.x 列数据，先用 broad_sample 建立对应关系，然后删除。\n",
    "    how=\"left\", \n",
    "    left_on=\"index\", # <=== Rows\n",
    "    right_on=\"broad_sample\"\n",
    ").drop(\"broad_sample\",axis=1)\n",
    "\n",
    "# Annotate columns\n",
    "#　index　和 variable 是一个东西，都表示 Treatment，但是 index　对应 Metadata_moa.x_x\t，variable对应Metadata_moa.x_y\n",
    "df2 = pd.merge(\n",
    "    df2, profiles[[\"broad_sample\", \"moa\"]],\n",
    "    how=\"left\", \n",
    "    left_on=\"variable\", # <=== Columns\n",
    "    right_on=\"broad_sample\"\n",
    ").drop(\"broad_sample\",axis=1)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8100, 5)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and save\n",
    "df2.columns = [\"Var1\", \"Var2\", \"value\", \"Metadata_moa.x\", \"Metadata_moa.y\"]\n",
    "\n",
    "# # MOA Evaluation using enrichment analysis\n",
    "\n",
    "SIM_MATRIX = df2  # \"data/cos_efn128combinedplatesout_conv6a_1e-2_e30.csv\"\n",
    "# OUT_RESUTS = \"output/efn128combinedplatesout_conv6a_1e-2_e30\"\n",
    "\n",
    "def load_similarity_matrix(cr_mat):\n",
    "    # Load matrix in triplet format and reshape\n",
    "    # cr_mat = pd.read_csv(filename)\n",
    "    X = cr_mat.pivot(index=\"Var1\", columns=\"Var2\", values=\"value\").reset_index()\n",
    "    \n",
    "    # Identify annotations\n",
    "    Y = cr_mat.groupby(\"Var1\").max().reset_index()\n",
    "    Y = Y[~Y[\"Metadata_moa.x\"].isna()].sort_values(by=\"Var1\")\n",
    "    \n",
    "    # Make sure the matrix is sorted by treatment\n",
    "    X = X.loc[X.Var1.isin(Y.Var1), [\"Var1\"] + list(Y.Var1)].sort_values(\"Var1\")\n",
    "    \n",
    "    return X,Y\n",
    "\n",
    "X, Y = load_similarity_matrix(SIM_MATRIX)  # X 加载了数值, Y 加载了treatment等信息，最后变成随机量。\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_567401/1900701817.py:25: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  candidates.append(Y[\"Ref_moa\"].str.contains(reg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Precision metrics: {'P@5': 0.03255813953488373, 'P@10': 0.02441860465116279, 'P@20': 0.020348837209302327, 'P@50': 0.013720930232558142, 'P@100': 0.01, 'P@1%': 0.05813953488372093, 'P@3%': 0.05813953488372093, 'P@5%': 0.0377906976744186, 'P@10%': 0.02454780361757106, 'P@20%': 0.020671834625322995}\n",
      "Recall metrics: {'R@1%': {'value': 0.029069767441860465, 'baseline': 0.02172839506172839, 'improvement': 1.3378699788583512}, 'R@3%': {'value': 0.05813953488372093, 'baseline': 0.02172839506172839, 'improvement': 2.6757399577167025}, 'R@5%': {'value': 0.0755813953488372, 'baseline': 0.02172839506172839, 'improvement': 3.478461945031713}, 'R@10%': {'value': 0.11046511627906977, 'baseline': 0.02172839506172839, 'improvement': 5.083905919661735}, 'R@20%': {'value': 0.18604651162790697, 'baseline': 0.02172839506172839, 'improvement': 8.562367864693448}}\n",
      "MAP: 0.06817616904687326\n",
      "Average folds of enrichment at top 1%: 5.116279069767442\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "# MOA matching\n",
    "\n",
    "Y.groupby(\"Metadata_moa.x\")[\"Var1\"].count()  # 找到每一种 MOA 中 Var1：Treatment 的数量\n",
    "\n",
    "moa_matches = []\n",
    "Y[\"Ref_moa\"] = Y[\"Metadata_moa.x\"].str.replace('|', '___')  #　potassium channel activator\t\n",
    "# Y['Metadata_moa.x'][63] \n",
    "\n",
    "# MOA 是 Metadata_moa.x 的内部结果，如果 Metadata_moa.x 包含多个预测，则 MOA 中包含多个 True\n",
    "Y[\"Ref_moa\"] = Y[\"Metadata_moa.x\"].str.replace('|', '___')  #　内部包含多项的预测，替换后方便使用正则表达式进行匹配。 'norepinephrine reuptake inhibitor|tricyclic antidepressant'\n",
    "for k,r in Y.iterrows():\n",
    "    moas = r[\"Metadata_moa.x\"].split(\"|\")\n",
    "    # print(moas)\n",
    "    candidates = []\n",
    "    for m in moas:\n",
    "        reg = r'(^|___){}($|___)'.format(m)  \n",
    "        '''\n",
    "        正则表达式：\n",
    "        匹配字符串 m，并确保它要么出现在字符串的开头或结尾，要么被三个下划线分隔。例如，如果 m 是 example，那么生成的正则表达式将是 (^|___)example($|___)，它可以匹配以下情况：\n",
    "        example 在字符串的开头或结尾。\n",
    "        example 被 ___ 分隔，如 ___example___。\n",
    "        '''\n",
    "        candidates.append(Y[\"Ref_moa\"].str.contains(reg))\n",
    "        # print('reg', reg, candidates[:20])\n",
    "    matches = candidates[0]\n",
    "    for c in candidates:\n",
    "        # print(\"22\", matches, c)\n",
    "        matches = matches | c\n",
    "    moa_matches.append(matches)\n",
    "    # break\n",
    "\n",
    "moa_matches = np.asarray(moa_matches)\n",
    "# plt.imshow(moa_matches)\n",
    "\n",
    "\n",
    "# # Enrichment analysis\n",
    "\n",
    "# %% [markdown]\n",
    "# # 输入\n",
    "# 相似矩阵 (SIM)：一个表示样本或基因之间相似性的矩阵。\n",
    "# 匹配数据 (moa_matches)：一个包含匹配信息的数据集。\n",
    "# 阈值 (threshold)：一个数值参数，用于控制分析的严格程度。\n",
    "# # 输出\n",
    "# 富集结果：通常是一个包含富集分析结果的列表或数据框，可能包括显著性值、富集分数等。\n",
    "# 可视化图表：一些函数可能会生成热图、条形图等用于展示富集结果的图表。\n",
    "\n",
    "results = {}\n",
    "SIM = np.asarray(X[Y.Var1])\n",
    "# print(\"SIM:\", SIM.shape)  # (995, 995)\n",
    "# print(SIM)\n",
    "\n",
    "is_query = moa_matches.sum(axis=0) > 1 \n",
    "#　计算 moa_matches 每列的和，并判断是否大于1，结果存储在布尔数组 is_query 中。 大于1：表示该列中至少有两个或更多的非零值。这意味着在 moa_matches 中，该列有多个匹配项。\n",
    "\n",
    "for i in range(SIM.shape[0]):\n",
    "    if is_query[i]: #　如果 is_query 中对应位置为 True, 即大于1，有多个匹配项的情况。才能计算富集分析。\n",
    "        idx = [x for x in range(SIM.shape[1]) if x != i] #　创建一个索引列表 idx，包含除了当前行 i 之外的所有列索引。除开对角线。\n",
    "        results[i] = enrichment_analysis(SIM[i,idx], moa_matches[i,idx], 99.) # 确认这两个列表中，匹配情况是否高于随即情况\n",
    "        # 对 SIM 的第 i 行（去掉第 i 列）和 moa_matches 的第 i 行（去掉第 i 列）进行富集分析，并将结果存储在 results 的第 i 个位置。\n",
    "        if results[i][\"ods_ratio\"] is np.nan: # ods_ratio大于1 表明SIM[i,idx]中命中的概率高于在 moa_matches[i, idx] 中的概率\n",
    "            print(results[i][\"V\"], i)\n",
    "# results\n",
    "\n",
    "# 计算并打印富集分析结果中 ods_ratio 的平均值\n",
    "# 大于 1 则表明： SIM[i, idx] 中，该事件或特征更为显著或富集\n",
    "\n",
    "folds = [results[x][\"ods_ratio\"] for x in results] # 提取所有 ods_ratio\n",
    "enrichment_top_1 = np.mean(folds)\n",
    "# print(\"Average folds of enrichment at top 1%:\", enrichment_top_1)\n",
    "\n",
    "\n",
    "enrichment_results = pd.DataFrame(data=results).T\n",
    "# enrichment_results\n",
    "\n",
    "# # Average precision analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def precision_at_k(sim_matrix, moa_matches, k):\n",
    "    \"\"\"Calculate precision at k for each query\"\"\"\n",
    "    results = {}\n",
    "    is_query = moa_matches.sum(axis=0) > 1  # Only calculate for queries with multiple positives\n",
    "    \n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i]:\n",
    "            ranking = np.argsort(-sim_matrix[i, :])  # Descending order\n",
    "            top_k_matches = moa_matches[i, ranking[1:k+1]]  # Exclude self, get top k\n",
    "            pk = np.sum(top_k_matches) / k\n",
    "            results[i] = {\"precision_at_k\": pk, \"k\": k}\n",
    "    return results\n",
    "\n",
    "def recall_at_k(sim_matrix, moa_matches, k):\n",
    "    \"\"\"Calculate recall at k for each query\"\"\"\n",
    "    results = {}\n",
    "    is_query = moa_matches.sum(axis=0) > 1\n",
    "    total_positives = moa_matches.sum(axis=1)\n",
    "    \n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i] and total_positives[i] > 0:\n",
    "            ranking = np.argsort(-sim_matrix[i, :])\n",
    "            top_k_matches = moa_matches[i, ranking[1:k+1]]\n",
    "            recall = np.sum(top_k_matches) / total_positives[i]\n",
    "            results[i] = {\n",
    "                \"recall_at_k\": recall,\n",
    "                \"baseline_recall\": np.mean(moa_matches),  # Random baseline\n",
    "                \"k\": k\n",
    "            }\n",
    "    return results\n",
    "\n",
    "def evaluate_model(sim_matrix, moa_matches):\n",
    "    \"\"\"Comprehensive evaluation of retrieval performance\"\"\"\n",
    "    # Fixed evaluation points\n",
    "    evaluation_points = [5, 10, 20, 50, 100]\n",
    "    evaluation_percents = [1, 3, 5, 10, 20]\n",
    "    \n",
    "    # Calculate absolute positions for percentages\n",
    "    n = sim_matrix.shape[0]\n",
    "    percent_positions = [max(int(n * p/100), 1) for p in evaluation_percents]\n",
    "    \n",
    "    # Store all results\n",
    "    results = {\n",
    "        'precision': {},\n",
    "        'recall': {},\n",
    "        'metrics': {}\n",
    "    }\n",
    "    \n",
    "    # Calculate precision@k\n",
    "    for k in evaluation_points:\n",
    "        prec_k = precision_at_k(sim_matrix, moa_matches, k)\n",
    "        avg_prec = np.mean([prec_k[q][\"precision_at_k\"] for q in prec_k])\n",
    "        results['precision'][f'P@{k}'] = avg_prec\n",
    "    \n",
    "    # Calculate recall@k and recall@%\n",
    "    for pos, percent in zip(percent_positions, evaluation_percents):\n",
    "        # Precision at percentage\n",
    "        prec_p = precision_at_k(sim_matrix, moa_matches, pos)\n",
    "        avg_prec_p = np.mean([prec_p[q][\"precision_at_k\"] for q in prec_p])\n",
    "        results['precision'][f'P@{percent}%'] = avg_prec_p\n",
    "        \n",
    "        # Recall at percentage\n",
    "        recall_p = recall_at_k(sim_matrix, moa_matches, pos)\n",
    "        avg_recall_p = np.mean([recall_p[q][\"recall_at_k\"] for q in recall_p])\n",
    "        baseline_p = np.mean([recall_p[q][\"baseline_recall\"] for q in recall_p])\n",
    "        results['recall'][f'R@{percent}%'] = {\n",
    "            'value': avg_recall_p,\n",
    "            'baseline': baseline_p,\n",
    "            'improvement': avg_recall_p / baseline_p if baseline_p > 0 else np.nan\n",
    "        }\n",
    "    \n",
    "    # Calculate MAP (Mean Average Precision)\n",
    "    map_score = calculate_map(sim_matrix, moa_matches)\n",
    "    results['metrics']['MAP'] = map_score\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_map(sim_matrix, moa_matches):\n",
    "    \"\"\"Calculate Mean Average Precision without interpolation\"\"\"\n",
    "    aps = []\n",
    "    is_query = moa_matches.sum(axis=0) > 1\n",
    "    total_positives = moa_matches.sum(axis=1)\n",
    "    \n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i] and total_positives[i] > 0:\n",
    "            ranking = np.argsort(-sim_matrix[i, :])\n",
    "            relevant = moa_matches[i, ranking[1:]]  # Exclude self\n",
    "            \n",
    "            # Calculate precision at each rank where recall increases\n",
    "            precisions = []\n",
    "            true_positives = 0\n",
    "            for k in range(len(relevant)):\n",
    "                if relevant[k]:\n",
    "                    true_positives += 1\n",
    "                    precisions.append(true_positives / (k + 1))\n",
    "            \n",
    "            if precisions:\n",
    "                ap = np.sum(precisions) / total_positives[i]\n",
    "                aps.append(ap)\n",
    "    \n",
    "    return np.mean(aps) if aps else 0\n",
    "\n",
    "# Example usage:\n",
    "results = evaluate_model(SIM, moa_matches)\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"Precision metrics:\", results['precision'])\n",
    "print(\"Recall metrics:\", results['recall'])\n",
    "print(\"MAP:\", results['metrics']['MAP'])\n",
    "\n",
    "print(\"Average folds of enrichment at top 1%:\", enrichment_top_1)\n",
    "# print(\"Mean Average Precision (MAP): \\t\", np.mean(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
