{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SQ00014816-16 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.transform import resize\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from huggingface_mae import MAEModel\n",
    "from utils import *\n",
    "\n",
    "class PDDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, CSV_path):\n",
    "        self.image_path = image_path\n",
    "        self.image_files_CSV = pd.read_csv(CSV_path, header=None)  # 只取文件名列\n",
    "        self.image_files = self.image_files_CSV[0].tolist()\n",
    "        self.total_images = len(self.image_files)\n",
    "        print(len(self.image_files))\n",
    "        \n",
    "        # 确保图像数量是5的倍数\n",
    "        assert self.total_images % 5 == 0, \"图像总数必须是5的倍数\"\n",
    "        self.num_groups = self.total_images // 5\n",
    "        \n",
    "        # 预处理转换\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def load_image(self, img_name):\n",
    "        img_path = os.path.join(self.image_path, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        return np.array(image)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 计算5个图像的起始位置\n",
    "        start_idx = idx * 5\n",
    "        \n",
    "        # 加载5个连续的图像\n",
    "        images = []\n",
    "        for i in range(5):\n",
    "            img_name = self.image_files[start_idx + i]\n",
    "            img_array = self.load_image(img_name)\n",
    "            images.append(img_array)\n",
    "        \n",
    "        # 堆叠图像并调整大小 (5, H, W) -> (5, 448, 448)\n",
    "        images = np.stack(images, axis=0)\n",
    "        images = resize(images, (5, 256, 256), anti_aliasing=True)\n",
    "        \n",
    "        # 转换为张量 (5, 448, 448) -> (5, 448, 448)\n",
    "        images = torch.from_numpy(images).float()\n",
    "        \n",
    "        return {'image': images}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17280"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "image_files = pd.read_csv(\"/data/boom/cpg0004/images/2016_04_01_a549_48hr_batch1_compressed/images/SQ00014816.csv\", header=None)  # 只取文件名列\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loaders_inference(batch_size):\n",
    "    print(\"Building loaders\")\n",
    "    dataset = PDDDataset(\n",
    "        image_path=\"/data/boom/cpg0004/images/2016_04_01_a549_48hr_batch1_compressed/images/SQ00014816/\",\n",
    "        CSV_path=\"/data/boom/cpg0004/images/2016_04_01_a549_48hr_batch1_compressed/images/SQ00014816.csv\"\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=4, \n",
    "        pin_memory=True, \n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    print(f\"Total batches: {len(test_loader)}\")\n",
    "    return test_loader\n",
    "\n",
    "def get_image_embeddings(model_path, model, batch_size):\n",
    "    test_loader = build_loaders_inference(batch_size)\n",
    "    model = model.eval().cuda()\n",
    "    \n",
    "    print(\"Finished loading model\")\n",
    "    test_image_embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            \n",
    "            # Run prediction\n",
    "            model.return_channelwise_embeddings = False\n",
    "            image_embeddings = model.predict(batch[\"image\"].cuda())\n",
    "            \n",
    "            # Reshape back if needed (depending on your model output)\n",
    "            test_image_embeddings.append(image_embeddings)\n",
    "            # print(image_embeddings.shape)\n",
    "            # break\n",
    "    \n",
    "    return torch.cat(test_image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bob/boom/PhenoProfiler/Baseline/OpenPhenom/huggingface_mae.py:291: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(modelpath, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building loaders\n",
      "17280\n",
      "Total batches: 18\n",
      "Finished loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]/home/bob/anaconda3/envs/boom/lib/python3.11/site-packages/torch/nn/modules/instancenorm.py:88: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
      "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n",
      "100%|██████████| 18/18 [01:51<00:00,  6.17s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"recursionpharma/OpenPhenom\"\n",
    "save_path = \"output/SQ00014816/\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# 加载模型\n",
    "model = MAEModel.from_pretrained(MODEL_PATH).cuda()\n",
    "img_embeddings = get_image_embeddings(MODEL_PATH, model, batch_size=200)  # change batch_size to fit your device\n",
    "features = img_embeddings.cpu().numpy()\n",
    "\n",
    "np.save(save_path + \"OpenPhenom_SQ00014816_test\" + \".npy\", features.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3456, 384)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3456, 384)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "save_path = \"output/SQ00014816/\"\n",
    "\n",
    "features = np.load(save_path+\"OpenPhenom_SQ00014816_test.npy\").T\n",
    "# save_path = 'output/SQ00014816/'\n",
    "REG_PARAM = 1e-2\n",
    "num_features = features.shape[1]\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make GT of MOA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13553, 18)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_meta = pd.read_csv('/home/bob/boom/PhenoProfiler/Baseline/lincs-cell-painting/metadata/moa/repurposing_info.tsv', sep='\\t')  # assuming it's tab-delimited\n",
    "print(all_meta.shape)  # meta['moa']\n",
    "# all_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1437"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_meta['moa'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "填充后的 moa 列统计：\n",
      "42 个缺失值剩余\n",
      "24 个缺失值剩余\n"
     ]
    }
   ],
   "source": [
    "# find plate name by dict barcode_platemap\n",
    "repurposing_info = pd.read_csv('/home/bob/boom/PhenoProfiler/Baseline/lincs-cell-painting/metadata/platemaps/2016_04_01_a549_48hr_batch1/barcode_platemap.csv')\n",
    "# repurposing_info.head()\n",
    "\n",
    "# 创建字典，Assay_Plate_Barcode为键，Plate_Map_Name为值\n",
    "barcode_to_platemap = dict(zip(repurposing_info['Assay_Plate_Barcode'], repurposing_info['Plate_Map_Name']))\n",
    "plate = barcode_to_platemap['SQ00014816']\n",
    "\n",
    "plate_path = f'/home/bob/boom/PhenoProfiler/Baseline/lincs-cell-painting/metadata/platemaps/2016_04_01_a549_48hr_batch1/platemap/{plate}.txt'\n",
    "\n",
    "palte_meta = pd.read_csv(plate_path, sep='\\t')\n",
    "\n",
    "# print(plate_path, '\\n', palte_meta.head())\n",
    "\n",
    "# 假设 meta 和 palte_meta 是已经加载的 DataFrame\n",
    "palte_meta_updated = pd.merge(\n",
    "    palte_meta,\n",
    "    all_meta[['broad_id', 'moa']],  # 选择需要的列\n",
    "    left_on='broad_sample',\n",
    "    right_on='broad_id',\n",
    "    how='left'  # 保留 palte_meta 的所有行，即使没有匹配\n",
    ")\n",
    "\n",
    "# 如果合并后不需要 broad_id 列（因为它和 broad_sample 相同），可以删除\n",
    "palte_meta_updated.drop(columns=['broad_id'], inplace=True, errors='ignore')\n",
    "palte_meta_updated['broad_sample'] = palte_meta_updated['broad_sample'].fillna(\"DMSO\")\n",
    "\n",
    "# 用补充文件（/home/bob/boom/PhenoProfiler/Baseline/lincs-cell-painting/metadata/moa/repurposing_info_external_moa_map_resolved.tsv）来进一步筛选\n",
    "\n",
    "# 1. 读取外部 TSV 文件\n",
    "external_moa_path = \"/home/bob/boom/PhenoProfiler/Baseline/lincs-cell-painting/metadata/moa/repurposing_info_external_moa_map_resolved.tsv\"\n",
    "external_moa_df = pd.read_csv(external_moa_path, sep='\\t')\n",
    "\n",
    "# 2. 创建 broad_sample → moa 的映射字典\n",
    "moa_mapping = external_moa_df.set_index('broad_sample')['moa'].to_dict()\n",
    "\n",
    "# 3. 填充 palte_meta_updated 的 moa 缺失值\n",
    "palte_meta_updated['moa'] = palte_meta_updated['moa'].fillna(\n",
    "    palte_meta_updated['broad_sample'].map(moa_mapping)\n",
    ")\n",
    "\n",
    "# 检查填充结果\n",
    "print(\"填充后的 moa 列统计：\")\n",
    "print(palte_meta_updated['moa'].isna().sum(), \"个缺失值剩余\")\n",
    "print(palte_meta_updated['mmoles_per_liter'].isna().sum(), \"个缺失值剩余\")\n",
    "\n",
    "meta = palte_meta_updated\n",
    "# meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n",
      "/tmp/ipykernel_1670793/3954228510.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  result_df[feature_columns] = aggregated_features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(384, 387)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整合成 Well Trt Features 的形式\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "save_path = 'output/SQ00014816/'\n",
    "REG_PARAM = 1e-2\n",
    "# num_features = 672\n",
    "\n",
    "# features = np.load(save_path + \"PhenoProfiler_alltrain_25test.npy\").T\n",
    "# meta = pd.read_csv('output/JUMP-MOA_compound_platemap_with_metadata.txt', sep='\\t')\n",
    "\n",
    "# 检查数据形状是否匹配\n",
    "# assert len(meta) == features.shape[0] // 45, \"Meta数据行数与特征数据不匹配\"\n",
    "\n",
    "# 特征聚合：每4行取平均\n",
    "aggregated_features = np.zeros((len(meta), num_features))\n",
    "for i in range(len(meta)):\n",
    "    start_idx = i * 9\n",
    "    end_idx = start_idx + 9\n",
    "    aggregated_features[i] = features[start_idx:end_idx].mean(axis=0)\n",
    "\n",
    "# 创建结果DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'Well': meta['well_position'],\n",
    "    'broad_sample':meta['broad_sample'],\n",
    "    'moa': meta['moa'],\n",
    "})\n",
    "\n",
    "# 添加聚合后的特征\n",
    "feature_columns = [i for i in range(num_features)]\n",
    "result_df[feature_columns] = aggregated_features\n",
    "\n",
    "# 保存为CSV文件\n",
    "# output_path = save_path + 'PhenoProfiler_Wells_NoBC.csv'\n",
    "# result_df.to_csv(output_path, index=False)\n",
    "result_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BC Sphering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "import pandas as pd\n",
    "\n",
    "class WhiteningNormalizer(object):\n",
    "    def __init__(self, controls, reg_param=1e-6):\n",
    "        # Whitening transform on population level data\n",
    "        self.mu = controls.mean()\n",
    "        self.whitening_transform(controls - self.mu, reg_param, rotate=True)\n",
    "        # print(self.mu.shape, self.W.shape)\n",
    "        \n",
    "    def whitening_transform(self, X, lambda_, rotate=True):\n",
    "        C = (1/X.shape[0]) * np.dot(X.T, X)\n",
    "        s, V = scipy.linalg.eigh(C)\n",
    "        D = np.diag( 1. / np.sqrt(s + lambda_) )\n",
    "        W = np.dot(V, D)\n",
    "        if rotate:\n",
    "            W = np.dot(W, V.T)\n",
    "        self.W = W\n",
    "\n",
    "    def normalize(self, X):\n",
    "        return np.dot(X - self.mu, self.W)\n",
    "\n",
    "columns2 = [i for i in range(num_features)]  #　(672)\n",
    "REG_PARAM = 1e-2\n",
    "\n",
    "wells = result_df\n",
    "whN = WhiteningNormalizer(wells.loc[wells[\"broad_sample\"] == \"DMSO\", columns2], reg_param=REG_PARAM)\n",
    "\n",
    "whD = whN.normalize(wells[columns2])\n",
    "\n",
    "# Save whitened profiles\n",
    "wells[columns2] = whD\n",
    "\n",
    "# wells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 387)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wells.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment-level profiles / Mean Aggreagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Well</th>\n",
       "      <th>broad_sample</th>\n",
       "      <th>moa</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>-0.031421</td>\n",
       "      <td>0.019696</td>\n",
       "      <td>-0.059950</td>\n",
       "      <td>0.070879</td>\n",
       "      <td>0.049661</td>\n",
       "      <td>0.012875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210351</td>\n",
       "      <td>-0.094434</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>-0.067272</td>\n",
       "      <td>-0.067312</td>\n",
       "      <td>-0.028764</td>\n",
       "      <td>0.157191</td>\n",
       "      <td>0.045403</td>\n",
       "      <td>-0.064931</td>\n",
       "      <td>-0.007419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008721</td>\n",
       "      <td>-0.008878</td>\n",
       "      <td>-0.026377</td>\n",
       "      <td>0.105692</td>\n",
       "      <td>0.055148</td>\n",
       "      <td>0.057425</td>\n",
       "      <td>-0.130773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094975</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>0.031881</td>\n",
       "      <td>0.059962</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>0.039129</td>\n",
       "      <td>0.114449</td>\n",
       "      <td>0.029350</td>\n",
       "      <td>0.040222</td>\n",
       "      <td>0.115985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>-0.059426</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>0.099663</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>-0.050077</td>\n",
       "      <td>0.028487</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.068385</td>\n",
       "      <td>0.137990</td>\n",
       "      <td>0.127662</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>0.038972</td>\n",
       "      <td>-0.057043</td>\n",
       "      <td>0.057438</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.178774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019775</td>\n",
       "      <td>-0.036350</td>\n",
       "      <td>0.036985</td>\n",
       "      <td>-0.008255</td>\n",
       "      <td>-0.047437</td>\n",
       "      <td>0.166910</td>\n",
       "      <td>-0.079371</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044420</td>\n",
       "      <td>-0.054061</td>\n",
       "      <td>-0.076688</td>\n",
       "      <td>-0.104945</td>\n",
       "      <td>0.074443</td>\n",
       "      <td>-0.082896</td>\n",
       "      <td>-0.022052</td>\n",
       "      <td>-0.018389</td>\n",
       "      <td>-0.074130</td>\n",
       "      <td>-0.046701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>-0.025960</td>\n",
       "      <td>-0.013322</td>\n",
       "      <td>0.062294</td>\n",
       "      <td>0.024337</td>\n",
       "      <td>-0.016696</td>\n",
       "      <td>-0.034603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015249</td>\n",
       "      <td>0.084324</td>\n",
       "      <td>-0.043028</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.037843</td>\n",
       "      <td>-0.076022</td>\n",
       "      <td>0.015151</td>\n",
       "      <td>-0.101998</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>-0.025105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Well broad_sample  moa         0         1         2         3         4  \\\n",
       "0  A01          NaN  NaN  0.024124 -0.031421  0.019696 -0.059950  0.070879   \n",
       "1  A02          NaN  NaN -0.008721 -0.008878 -0.026377  0.105692  0.055148   \n",
       "2  A03          NaN  NaN  0.016377 -0.059426 -0.012014  0.099663  0.014628   \n",
       "3  A04          NaN  NaN  0.019775 -0.036350  0.036985 -0.008255 -0.047437   \n",
       "4  A05          NaN  NaN  0.008126 -0.025960 -0.013322  0.062294  0.024337   \n",
       "\n",
       "          5         6  ...       374       375       376       377       378  \\\n",
       "0  0.049661  0.012875  ... -0.210351 -0.094434  0.056357 -0.067272 -0.067312   \n",
       "1  0.057425 -0.130773  ... -0.094975  0.026888  0.031881  0.059962  0.001361   \n",
       "2 -0.050077  0.028487  ... -0.003123 -0.068385  0.137990  0.127662  0.011759   \n",
       "3  0.166910 -0.079371  ... -0.044420 -0.054061 -0.076688 -0.104945  0.074443   \n",
       "4 -0.016696 -0.034603  ... -0.015249  0.084324 -0.043028  0.005511  0.037843   \n",
       "\n",
       "        379       380       381       382       383  \n",
       "0 -0.028764  0.157191  0.045403 -0.064931 -0.007419  \n",
       "1  0.039129  0.114449  0.029350  0.040222  0.115985  \n",
       "2  0.038972 -0.057043  0.057438  0.004664  0.178774  \n",
       "3 -0.082896 -0.022052 -0.018389 -0.074130 -0.046701  \n",
       "4 -0.076022  0.015151 -0.101998  0.002877 -0.025105  \n",
       "\n",
       "[5 rows x 387 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将 'DMSO' 替换为 NaN\n",
    "wells['broad_sample'] = wells['broad_sample'].replace('DMSO', np.nan)\n",
    "wells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 386)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "# Aggregate profiles\n",
    "columns1 = [\"Well\", \"broad_sample\"]\n",
    "columns2 = [i for i in range(num_features)]\n",
    "\n",
    "wells_1 = wells.drop(columns=[\"Well\"])\n",
    "\n",
    "profiles = wells_1.groupby([\"broad_sample\", 'moa']).mean().reset_index()\n",
    "\n",
    "# 将 meta 的 broad_sample 和 moa 转为字典\n",
    "moa_dict = meta.set_index('broad_sample')['moa'].to_dict()\n",
    "\n",
    "# 用 map 添加 moa 列\n",
    "profiles['moa'] = profiles['broad_sample'].map(moa_dict)\n",
    "\n",
    "# profiles = wells_1[[\"Treatment\", \"broad_sample\"] + columns2]\n",
    "# # profiles\n",
    "print(profiles.shape)\n",
    "# profiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 55)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 6. Similarity matrix\n",
    "# Compute Cosine Similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "COS = cosine_similarity(profiles[columns2], profiles[columns2])\n",
    "COS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>moa_x</th>\n",
       "      <th>moa_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRD-A67862938-034-14-9</td>\n",
       "      <td>BRD-A67862938-034-14-9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>adrenergic receptor antagonist</td>\n",
       "      <td>adrenergic receptor antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRD-A68281735-001-18-6</td>\n",
       "      <td>BRD-A67862938-034-14-9</td>\n",
       "      <td>0.312084</td>\n",
       "      <td>leukotriene receptor antagonist|lipoxygenase i...</td>\n",
       "      <td>adrenergic receptor antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRD-A68304895-003-02-2</td>\n",
       "      <td>BRD-A67862938-034-14-9</td>\n",
       "      <td>0.253882</td>\n",
       "      <td>dopamine reuptake inhibitor</td>\n",
       "      <td>adrenergic receptor antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRD-A68493689-001-01-9</td>\n",
       "      <td>BRD-A67862938-034-14-9</td>\n",
       "      <td>0.263021</td>\n",
       "      <td>HCV inhibitor</td>\n",
       "      <td>adrenergic receptor antagonist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRD-A68888262-003-15-1</td>\n",
       "      <td>BRD-A67862938-034-14-9</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>histamine receptor antagonist</td>\n",
       "      <td>adrenergic receptor antagonist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    index                variable     value  \\\n",
       "0  BRD-A67862938-034-14-9  BRD-A67862938-034-14-9  1.000000   \n",
       "1  BRD-A68281735-001-18-6  BRD-A67862938-034-14-9  0.312084   \n",
       "2  BRD-A68304895-003-02-2  BRD-A67862938-034-14-9  0.253882   \n",
       "3  BRD-A68493689-001-01-9  BRD-A67862938-034-14-9  0.263021   \n",
       "4  BRD-A68888262-003-15-1  BRD-A67862938-034-14-9  0.012291   \n",
       "\n",
       "                                               moa_x  \\\n",
       "0                     adrenergic receptor antagonist   \n",
       "1  leukotriene receptor antagonist|lipoxygenase i...   \n",
       "2                        dopamine reuptake inhibitor   \n",
       "3                                      HCV inhibitor   \n",
       "4                      histamine receptor antagonist   \n",
       "\n",
       "                            moa_y  \n",
       "0  adrenergic receptor antagonist  \n",
       "1  adrenergic receptor antagonist  \n",
       "2  adrenergic receptor antagonist  \n",
       "3  adrenergic receptor antagonist  \n",
       "4  adrenergic receptor antagonist  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to tidy format\n",
    "df = pd.DataFrame(data=COS, index=list(profiles.broad_sample), columns=list(profiles.broad_sample))\n",
    "#　将行索引重置为默认整数索引，并将原来的行索引 broad_sample 转换为一列，命名为 index。所以，variable　表示原来的broad_sample名。\n",
    "df = df.reset_index().melt(id_vars=[\"index\"])\n",
    "# df # 其中每一行都表示 预测的Treatment和 GT 之间的概率。\n",
    "\n",
    "# Annotate rows\n",
    "df2 = pd.merge(\n",
    "    df, \n",
    "    profiles[[\"broad_sample\", \"moa\"]],  # 为了加 Metadata_moa.x 列数据，先用 broad_sample 建立对应关系，然后删除。\n",
    "    how=\"left\", \n",
    "    left_on=\"index\", # <=== Rows\n",
    "    right_on=\"broad_sample\"\n",
    ").drop(\"broad_sample\",axis=1)\n",
    "\n",
    "# Annotate columns\n",
    "#　index　和 variable 是一个东西，都表示 Treatment，但是 index　对应 Metadata_moa.x_x\t，variable对应Metadata_moa.x_y\n",
    "df2 = pd.merge(\n",
    "    df2, profiles[[\"broad_sample\", \"moa\"]],\n",
    "    how=\"left\", \n",
    "    left_on=\"variable\", # <=== Columns\n",
    "    right_on=\"broad_sample\"\n",
    ").drop(\"broad_sample\",axis=1)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3025, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns and save\n",
    "df2.columns = [\"Var1\", \"Var2\", \"value\", \"Metadata_moa.x\", \"Metadata_moa.y\"]\n",
    "\n",
    "# # MOA Evaluation using enrichment analysis\n",
    "\n",
    "SIM_MATRIX = df2  # \"data/cos_efn128combinedplatesout_conv6a_1e-2_e30.csv\"\n",
    "# OUT_RESUTS = \"output/efn128combinedplatesout_conv6a_1e-2_e30\"\n",
    "\n",
    "def load_similarity_matrix(cr_mat):\n",
    "    # Load matrix in triplet format and reshape\n",
    "    # cr_mat = pd.read_csv(filename)\n",
    "    X = cr_mat.pivot(index=\"Var1\", columns=\"Var2\", values=\"value\").reset_index()\n",
    "    \n",
    "    # Identify annotations - select only relevant columns before grouping\n",
    "    Y = cr_mat[[\"Var1\", \"Metadata_moa.x\"]].drop_duplicates()\n",
    "    Y = Y[~Y[\"Metadata_moa.x\"].isna()].sort_values(by=\"Var1\")\n",
    "    \n",
    "    # Make sure the matrix is sorted by treatment\n",
    "    X = X.loc[X.Var1.isin(Y.Var1), [\"Var1\"] + list(Y.Var1)].sort_values(\"Var1\")\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "X, Y = load_similarity_matrix(SIM_MATRIX)  # X 加载了数值, Y 加载了treatment等信息，最后变成随机量。\n",
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Precision metrics: {'P@5': 0.10666666666666666, 'P@10': 0.060000000000000005, 'P@20': 0.04000000000000001, 'P@50': 0.024000000000000004, 'P@100': 0.012000000000000002, 'P@1%': 0.4, 'P@3%': 0.4, 'P@5%': 0.26666666666666666, 'P@10%': 0.10666666666666666, 'P@20%': 0.05454545454545455}\n",
      "Recall metrics: {'R@1%': {'value': 0.18888888888888886, 'baseline': 0.022809917355371905, 'improvement': 8.28099838969404}, 'R@3%': {'value': 0.18888888888888886, 'baseline': 0.022809917355371905, 'improvement': 8.28099838969404}, 'R@5%': {'value': 0.24444444444444444, 'baseline': 0.022809917355371905, 'improvement': 10.716586151368759}, 'R@10%': {'value': 0.24444444444444444, 'baseline': 0.022809917355371905, 'improvement': 10.716586151368759}, 'R@20%': {'value': 0.27777777777777773, 'baseline': 0.022809917355371905, 'improvement': 12.177938808373588}}\n",
      "MAP: 0.23300160386735339\n",
      "Average folds of enrichment at top 1%: 21.133333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1670793/1900701817.py:25: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  candidates.append(Y[\"Ref_moa\"].str.contains(reg))\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "# MOA matching\n",
    "\n",
    "Y.groupby(\"Metadata_moa.x\")[\"Var1\"].count()  # 找到每一种 MOA 中 Var1：Treatment 的数量\n",
    "\n",
    "moa_matches = []\n",
    "Y[\"Ref_moa\"] = Y[\"Metadata_moa.x\"].str.replace('|', '___')  #　potassium channel activator\t\n",
    "# Y['Metadata_moa.x'][63] \n",
    "\n",
    "# MOA 是 Metadata_moa.x 的内部结果，如果 Metadata_moa.x 包含多个预测，则 MOA 中包含多个 True\n",
    "Y[\"Ref_moa\"] = Y[\"Metadata_moa.x\"].str.replace('|', '___')  #　内部包含多项的预测，替换后方便使用正则表达式进行匹配。 'norepinephrine reuptake inhibitor|tricyclic antidepressant'\n",
    "for k,r in Y.iterrows():\n",
    "    moas = r[\"Metadata_moa.x\"].split(\"|\")\n",
    "    # print(moas)\n",
    "    candidates = []\n",
    "    for m in moas:\n",
    "        reg = r'(^|___){}($|___)'.format(m)  \n",
    "        '''\n",
    "        正则表达式：\n",
    "        匹配字符串 m，并确保它要么出现在字符串的开头或结尾，要么被三个下划线分隔。例如，如果 m 是 example，那么生成的正则表达式将是 (^|___)example($|___)，它可以匹配以下情况：\n",
    "        example 在字符串的开头或结尾。\n",
    "        example 被 ___ 分隔，如 ___example___。\n",
    "        '''\n",
    "        candidates.append(Y[\"Ref_moa\"].str.contains(reg))\n",
    "        # print('reg', reg, candidates[:20])\n",
    "    matches = candidates[0]\n",
    "    for c in candidates:\n",
    "        # print(\"22\", matches, c)\n",
    "        matches = matches | c\n",
    "    moa_matches.append(matches)\n",
    "    # break\n",
    "\n",
    "moa_matches = np.asarray(moa_matches)\n",
    "# plt.imshow(moa_matches)\n",
    "\n",
    "\n",
    "# # Enrichment analysis\n",
    "\n",
    "# %% [markdown]\n",
    "# # 输入\n",
    "# 相似矩阵 (SIM)：一个表示样本或基因之间相似性的矩阵。\n",
    "# 匹配数据 (moa_matches)：一个包含匹配信息的数据集。\n",
    "# 阈值 (threshold)：一个数值参数，用于控制分析的严格程度。\n",
    "# # 输出\n",
    "# 富集结果：通常是一个包含富集分析结果的列表或数据框，可能包括显著性值、富集分数等。\n",
    "# 可视化图表：一些函数可能会生成热图、条形图等用于展示富集结果的图表。\n",
    "\n",
    "results = {}\n",
    "SIM = np.asarray(X[Y.Var1])\n",
    "# print(\"SIM:\", SIM.shape)  # (995, 995)\n",
    "# print(SIM)\n",
    "\n",
    "is_query = moa_matches.sum(axis=0) > 1 \n",
    "#　计算 moa_matches 每列的和，并判断是否大于1，结果存储在布尔数组 is_query 中。 大于1：表示该列中至少有两个或更多的非零值。这意味着在 moa_matches 中，该列有多个匹配项。\n",
    "\n",
    "for i in range(SIM.shape[0]):\n",
    "    if is_query[i]: #　如果 is_query 中对应位置为 True, 即大于1，有多个匹配项的情况。才能计算富集分析。\n",
    "        idx = [x for x in range(SIM.shape[1]) if x != i] #　创建一个索引列表 idx，包含除了当前行 i 之外的所有列索引。除开对角线。\n",
    "        results[i] = enrichment_analysis(SIM[i,idx], moa_matches[i,idx], 99.) # 确认这两个列表中，匹配情况是否高于随即情况\n",
    "        # 对 SIM 的第 i 行（去掉第 i 列）和 moa_matches 的第 i 行（去掉第 i 列）进行富集分析，并将结果存储在 results 的第 i 个位置。\n",
    "        if results[i][\"ods_ratio\"] is np.nan: # ods_ratio大于1 表明SIM[i,idx]中命中的概率高于在 moa_matches[i, idx] 中的概率\n",
    "            print(results[i][\"V\"], i)\n",
    "# results\n",
    "\n",
    "# 计算并打印富集分析结果中 ods_ratio 的平均值\n",
    "# 大于 1 则表明： SIM[i, idx] 中，该事件或特征更为显著或富集\n",
    "\n",
    "folds = [results[x][\"ods_ratio\"] for x in results] # 提取所有 ods_ratio\n",
    "enrichment_top_1 = np.mean(folds)\n",
    "# print(\"Average folds of enrichment at top 1%:\", enrichment_top_1)\n",
    "\n",
    "\n",
    "enrichment_results = pd.DataFrame(data=results).T\n",
    "# enrichment_results\n",
    "\n",
    "# # Average precision analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def precision_at_k(sim_matrix, moa_matches, k):\n",
    "    \"\"\"Calculate precision at k for each query\"\"\"\n",
    "    results = {}\n",
    "    is_query = moa_matches.sum(axis=0) > 1  # Only calculate for queries with multiple positives\n",
    "    \n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i]:\n",
    "            ranking = np.argsort(-sim_matrix[i, :])  # Descending order\n",
    "            top_k_matches = moa_matches[i, ranking[1:k+1]]  # Exclude self, get top k\n",
    "            pk = np.sum(top_k_matches) / k\n",
    "            results[i] = {\"precision_at_k\": pk, \"k\": k}\n",
    "    return results\n",
    "\n",
    "def recall_at_k(sim_matrix, moa_matches, k):\n",
    "    \"\"\"Calculate recall at k for each query\"\"\"\n",
    "    results = {}\n",
    "    is_query = moa_matches.sum(axis=0) > 1\n",
    "    total_positives = moa_matches.sum(axis=1)\n",
    "    \n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i] and total_positives[i] > 0:\n",
    "            ranking = np.argsort(-sim_matrix[i, :])\n",
    "            top_k_matches = moa_matches[i, ranking[1:k+1]]\n",
    "            recall = np.sum(top_k_matches) / total_positives[i]\n",
    "            results[i] = {\n",
    "                \"recall_at_k\": recall,\n",
    "                \"baseline_recall\": np.mean(moa_matches),  # Random baseline\n",
    "                \"k\": k\n",
    "            }\n",
    "    return results\n",
    "\n",
    "def evaluate_model(sim_matrix, moa_matches):\n",
    "    \"\"\"Comprehensive evaluation of retrieval performance\"\"\"\n",
    "    # Fixed evaluation points\n",
    "    evaluation_points = [5, 10, 20, 50, 100]\n",
    "    evaluation_percents = [1, 3, 5, 10, 20]\n",
    "    \n",
    "    # Calculate absolute positions for percentages\n",
    "    n = sim_matrix.shape[0]\n",
    "    percent_positions = [max(int(n * p/100), 1) for p in evaluation_percents]\n",
    "    \n",
    "    # Store all results\n",
    "    results = {\n",
    "        'precision': {},\n",
    "        'recall': {},\n",
    "        'metrics': {}\n",
    "    }\n",
    "    \n",
    "    # Calculate precision@k\n",
    "    for k in evaluation_points:\n",
    "        prec_k = precision_at_k(sim_matrix, moa_matches, k)\n",
    "        avg_prec = np.mean([prec_k[q][\"precision_at_k\"] for q in prec_k])\n",
    "        results['precision'][f'P@{k}'] = avg_prec\n",
    "    \n",
    "    # Calculate recall@k and recall@%\n",
    "    for pos, percent in zip(percent_positions, evaluation_percents):\n",
    "        # Precision at percentage\n",
    "        prec_p = precision_at_k(sim_matrix, moa_matches, pos)\n",
    "        avg_prec_p = np.mean([prec_p[q][\"precision_at_k\"] for q in prec_p])\n",
    "        results['precision'][f'P@{percent}%'] = avg_prec_p\n",
    "        \n",
    "        # Recall at percentage\n",
    "        recall_p = recall_at_k(sim_matrix, moa_matches, pos)\n",
    "        avg_recall_p = np.mean([recall_p[q][\"recall_at_k\"] for q in recall_p])\n",
    "        baseline_p = np.mean([recall_p[q][\"baseline_recall\"] for q in recall_p])\n",
    "        results['recall'][f'R@{percent}%'] = {\n",
    "            'value': avg_recall_p,\n",
    "            'baseline': baseline_p,\n",
    "            'improvement': avg_recall_p / baseline_p if baseline_p > 0 else np.nan\n",
    "        }\n",
    "    \n",
    "    # Calculate MAP (Mean Average Precision)\n",
    "    map_score = calculate_map(sim_matrix, moa_matches)\n",
    "    results['metrics']['MAP'] = map_score\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_map(sim_matrix, moa_matches):\n",
    "    \"\"\"Calculate Mean Average Precision without interpolation\"\"\"\n",
    "    aps = []\n",
    "    is_query = moa_matches.sum(axis=0) > 1\n",
    "    total_positives = moa_matches.sum(axis=1)\n",
    "    \n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        if is_query[i] and total_positives[i] > 0:\n",
    "            ranking = np.argsort(-sim_matrix[i, :])\n",
    "            relevant = moa_matches[i, ranking[1:]]  # Exclude self\n",
    "            \n",
    "            # Calculate precision at each rank where recall increases\n",
    "            precisions = []\n",
    "            true_positives = 0\n",
    "            for k in range(len(relevant)):\n",
    "                if relevant[k]:\n",
    "                    true_positives += 1\n",
    "                    precisions.append(true_positives / (k + 1))\n",
    "            \n",
    "            if precisions:\n",
    "                ap = np.sum(precisions) / total_positives[i]\n",
    "                aps.append(ap)\n",
    "    \n",
    "    return np.mean(aps) if aps else 0\n",
    "\n",
    "# Example usage:\n",
    "results = evaluate_model(SIM, moa_matches)\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"Precision metrics:\", results['precision'])\n",
    "print(\"Recall metrics:\", results['recall'])\n",
    "print(\"MAP:\", results['metrics']['MAP'])\n",
    "\n",
    "print(\"Average folds of enrichment at top 1%:\", enrichment_top_1)\n",
    "# print(\"Mean Average Precision (MAP): \\t\", np.mean(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
